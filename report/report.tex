\documentclass[12pt,a4paper,twoside]{report}

\input{setup}

%% Document
\begin{document}

%% Titlepage
\input{titlepage}

%% Page number for initial contents sections
\pagenumbering{roman}
\clearpage{\pagestyle{empty}\cleardoublepage}
\setcounter{page}{1}
\pagestyle{fancy}

%% Abstract
\begin{abstract}
Writing algorithms which can answer questions about a video - a task known as VideoQA - has long been a goal of artificial intelligence (AI) researchers. In order to correctly answer these questions, such algorithms are required to reason about physical and spatial properties of objects, as well as temporal sequences of frames.

Most existing VideoQA implementations make use of large neural networks, which require significant time and resources to train. These models also suffer from opacity; it is very difficult to understand what these models learn and how they come to their conclusions. Hybrid models - models which make use of both neural networks and symbolic reasoning - offer an alternative approach. Implemented correctly, hybrid models have the ability to recognise complex patterns in the video, as well as the ability to store knowledge, and reason about this knowledge, in an interpretable manner.

In this report, we present a novel, algorithmically generated VideoQA dataset, which models objects, relations and interactions between objects. The dataset contains seven different types of questions, each of which tests a model's intelligence in a particular way.

We also present a hybrid architecture for VideoQA tasks. This architecture combines the strengths of neural networks and symbolic reasoning, in order to understand: properties of objects, relations between objects and the occurrence of events in a video. We train a number of different models of this architecture on our VideoQA dataset, and evaluate each model's relative strengths and weaknesses. We show that one of these models can reason about uncertainty caused by errors and is able to answer over $99\%$ of questions in the testing data correctly. Finally, as part of our qualitative comparisons to existing implementations, we show that one of our models would be more adaptable to new environments than another recently proposed hybrid VideoQA model.
\end{abstract}

\cleardoublepage

%% Acknowledgements
\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
I am very grateful for the advice, support and patience of all four of my supervisors: Prof. Alessandra Russo, Dr. Krysia Broda, Dr. Jorge Lobo and Mr. David Tuckey. Thank you for investing so much time and effort in this project.

I would also like to say thanks to my friends and family for their continued support. I would also particularly like to say thanks to my parents for teaching me the importance of education.
\end{abstract}

\clearpage{\pagestyle{empty}\cleardoublepage}

%% Contents
\fancyhead[RE,LO]{\sffamily {Table of Contents}}
\tableofcontents

% TODO use or not?
\listoffigures
\listoftables

%% Page numbering for chapters
\clearpage{\pagestyle{empty}\cleardoublepage}
\pagenumbering{arabic}
\setcounter{page}{1}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}

%% Chapters
\subfile{chapters/intro}
\subfile{chapters/background}
\subfile{chapters/related}
\subfile{chapters/dataset}
\subfile{chapters/h-perl}
\subfile{chapters/hardcoded}
\subfile{chapters/trained}
\subfile{chapters/evaluation}
\subfile{chapters/conclusion}

%% Bibliography
\newpage
\printbibliography[heading=bibintoc]

%% Appendix
\newpage
\appendixtitleon
\appendixtitletocon
\begin{appendices}
\subfile{chapters/appendix-al}
\subfile{chapters/appendix-dataset}
\end{appendices}


\end{document}
