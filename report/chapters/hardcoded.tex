\documentclass[../report.tex]{subfiles}


\begin{document}


\chapter{Hardcoded Model}
\label{chapter:hardcoded}

Our first H-PERL implementation is the `hardcoded' model. The hardcoded model makes use of a mixture of manually engineered components and components which are trained on the full-data version of the OceanQA dataset. This model should not be taken as a solution to the general VideoQA problem, since it would be labourious to rewrite components for each new dataset environment. Instead we intend this model to be used as a benchmark for the OceanQA dataset, against which other VideoQA implementations can be evaluated.

Full details on the performance of the model, as well as the performance of some of the individual components is given in Chapter~\ref{chapter:evaluation}.


\section{Properties}

As mentioned in Chapter~\ref{chapter:h-perl}, the role of the properties component is to take an image of an object (as produced by the object detector) and, in the case of the OceanQA dataset, to return the colour and rotation of the object.

Since the object image is a 3D tensor\footnote{Height, width and RGB colour channels make up the three dimensions} of raw pixel values, a convolutional neural network is an excellent candidate for the implementation of the properties component. Other computer vision techniques for machine learning such as decision trees, random forests and SVMs require thousands of manually engineered filters to be applied to the image, whereas convolutional networks can learn a much smaller set of filters based on the training data.

Figure~\ref{fig:prop-network} shows the architecture of the properties network. The first part of this network encodes the object image into a 1024 dimenional latent vector using a series of convolutional and fully-connected layers. A set of fully-connected layers, one for each property, each take the vector encoding of the object and produce a vector of  real numbers. The size of each vector is equal to the number of possible values that property can take.

The final output of the network is a set of probability distributions, one for each property, over the set of possible values that property can take. As is standard in a multiclass classification problem, the softmax function is applied to each set of property values in order to construct the probability distribution. The softmax function guarantees that the elements of a vector sum to one and that each element is greater than or equal to zero, hence softmax creates a discrete probability distribution. The softmax function for a vector $\mathbf{z} \in \mathbb{R}^K$ is as follows:
\begin{equation}
  \sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}} \text{ for } i = 1,...,K
\end{equation}

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{prop-network}
  \caption{Architecture of the properties component neural network. An object is encoded into a latent vector, before a set of fully-connected layers produce a set of probability distributions over the property values. Batch normalisation is applied between convolutional layers. FM is a set of feature maps, the size of each feature map is given as the tuple (\textit{height}, \textit{width}, \textit{number of feature maps}).}
  \label{fig:prop-network}
\end{figure}

The full-data version of the OceanQA dataset labels both the colour and rotation of every object in every frame. This makes training a neural network relatively straightforward; we collate all of the objects and their properties in the dataset, resize each object image to 32x32 pixels, convert each property into a one-hot encoded vector and train the network using batches of 256 objects with a learning rate of 0.001 for 2 epochs. The cross-entropy loss is calculated for each property and these are summed to give an overall loss. The cross-entropy loss between a predicted probability distribution vector $\mathbf{p} \in \mathbb{R}^K$ and a one-hot encoded classification vector $\mathbf{y} \in \mathbb{R}^K$, where $K$ is the number of classes, is as follows:
\begin{equation}
  H(\mathbf{p}, \mathbf{y}) = - \sum_{c=1}^{K} y_c \text{ log}(p_c)
\end{equation}

When the H-PERL model is being evaluated each object image in the video is applied to the network (batched together for efficiency) and a set of probability distributions is produced. For each object, the property value for a particular property is given by the most probable element of the vector.


\section{Relations}

The job of the relations component is to list all instances of relevant binary relations between objects in each frame of the video. Since there is only one relevant binary relation in the OceanQA dataset, the job of this component is simply to list the instances of the \textit{close} relation.

The relations component of the hardcoded model contains a hand-written binary classification algorithm for determining whether two objects are close or not. For a given video, this algorithm is applied to every pair of objects in every frame of the video in order to list all instances of the relation. The object arguments of the closeness algorithm are given in symbolic form, rather than as raw pixel matrices. This means the algorithm is heavily reliant on accurate information from the object detector - the position tuple in particular. Although the closeness algorithm doesn't make use of the property component's extracted features, other algorithms for determining binary relations may require these.

The algorithm for determining the closeness of two objects is, in fact, identical to the algorithm used when constructing the dataset. The algorithm uses the idea of an expanded box around each object; the objects are close if their boxes overlap, as can be seen in Figure~\ref{fig:change-colour}. The algorithm was discussed alongside techniques used to create the dataset in Chapter~\ref{chapter:dataset} and is shown in Algorithm~\ref{algo:close_to}.

Clearly, since the algorithm used to construct the dataset and the algorithm used to find the relations between objects are exactly the same, the relations component achieves perfect accuracy provided the object detection is exactly correct. Although this may seem like cheating, since in general it is not possible to know the underlying rules of the dataset, we reiterate that the hardcoded model is not a solution to VideoQA tasks in general, but rather is specific to the OceanQA dataset, and can be used for comparisons with other models.

\begin{figure}[h]
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{change-colour-0.png}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{change-colour-1.png}
  \end{subfigure}
  \caption{Diagrams showing the octopus before and after moving close to a purple rock, and therefore turning purple itself. The brown dashed lines show the bounding boxes expanded by 5 pixels on each side around the objects. If these boxes overlap the objects are deemed to be close to one another.}
  \label{fig:change-colour}
\end{figure}

Another consideration for this approach to relation classification is speed; each relation classification algorithm (of which there is only one in the OceanQA dataset, but in general there may be many) looks at every possible pair of objects in every frame of the video. Assuming that each relation classifier operates in constant time, this creates an overall algorithmic complexity of $\mathcal{O}(kmn^2)$, where $k$ is the number of frames per video, $m$ is the number of relations to be classified and $n$ is the number of objects in each frame. Despite this we found that the time taken by the relation component was small relative to other components in the H-PERL model. Chapter~\ref{chapter:evaluation} outlines the full details of the component's performance, including details on the time taken during evaluation.


\section{Events}
\label{section:hardcoded-events}

As mentioned in Chapter~\ref{chapter:h-perl}, the role of the event detection component is to list all of the actions and effects which take place between each pair of consecutive frames of a given video. Since preceeding components have extracted a number of object- and frame-level symbolic features already, the event detector in the hardcoded model works only with these features, as opposed to viewing the raw pixels in each frame.

For the hardcoded model, the event detector is implemented by, firstly, searching through all possible combinations of actions. The component assumes that there is only one action per frame and that only non-static objects can be the cause of an action. Each combination of actions is then applied to a hand-written $\mathcal{AL}$ model of the environment to generate the set of symbolic features which would be expected to be observed should the set of actions have occurred. This set of features is then compared to the set of features which were actually observed - the set of features extracted by preceeding components. Finally, the combination of actions which lead to the best fit with the observed data are selected.

For each set of possible actions and their associated features generated by the $\mathcal{AL}$ model, a set of manually engineered ASP rules is used to find the corresponding set of effects. For example, if the octopus moves\footnote{Moving during frame $i$ refers to an object moving between frame $i$ and frame $i+1$.} during frame $i$ and is close to a blue rock during frame $i+1$, then we can infer that the \textit{change colour} effect occurs during frame $i$.


\subsection{The $\mathcal{AL}$ Model}

As described in Chapter~\ref{chapter:background}, $\mathcal{AL}$ is a formal model for describing the behaviour of a dynamic system. An $\mathcal{AL}$ system consists of a set of states and some way of transitioning between states using actions. We model our video as an $\mathcal{AL}$ system by considering each frame as a state and object actions between frames as $\mathcal{AL}$ actions. In $\mathcal{AL}$, a state is described by a set of fluents. Each fluent, $\textit{$<$f$>$}$, can be wrapped up in a predicate, $holds(\textit{$<$f$>$}, \textit{$<$i$>$})$, where \textit{$<$i$>$} is a timestep in the video, which means that fluent \textit{$<$f$>$} is true at step \textit{$<$i$>$}. Conversely, $\neg holds(\textit{$<$f$>$}, \textit{$<$i$>$})$ means that \textit{$<$f$>$} is not true at step \textit{$<$i$>$}. An OceanQA-specific example of a set of $\mathcal{AL}$ states and transitions between them is shown in Figure~\ref{fig:al-states}.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{al-states}
  \caption{A simplified example set of $\mathcal{AL}$ states and transitions. States which model the OceanQA environment contain many more fluents than are shown here.}
  \label{fig:al-states}
\end{figure}

As mentioned above, the optimal set of actions is found by comparing the observed features of the environment with an internal $\mathcal{AL}$ model of the environment. In the rest of this section we outline the $\mathcal{AL}$ system description for the OceanQA environment. This system description can then be written in ASP using the encoding provided in Appendix~\ref{appendix-al}.

Firstly, we outline the types involved in the $\mathcal{AL}$ system description, which are as follows:
\begin{itemize}
  \item Properties, including class and position, are modelled as \textit{inertial fluents} - their values can change as a direct result of the actions taken. Notice, however, that the number of possible position values is very large - $256^4$, hence, rather than allowing all possible values, we only include values that have been observed in the video, all other values are not modelled. This applies to all properties, class and position fluents.

  \item An additional inertial fluent, $exists(\textit{$<$id$>$})$, is also required. Intuitively, it means that an object with identifier \textit{$<$id$>$} is present in the current timestep.

  \item The close relation, which is written in ASP as $close(\mathit{Id1}, \mathit{Id2})$ when an object with identifier $\mathit{Id1}$ is close to an object with identifier $\mathit{Id2}$, is considered a \textit{defined fluent}. Although they are modelled as defined fluents, their thruthiness cannot be altered by the events component, since relation classification is handled by the relations component. Therefore, these fluents are copied directly across from the observed data into the $\mathcal{AL}$ model.

  \item We add a further defined fluent, which also comes directly from the observed information. This fluent is called $disappear(\textit{$<$id$>$})$, and, naturally, means that an object with identifier \textit{$<$id$>$} disappears immediately after the current timestep.

  \item Actions are, of course, modelled by the \textit{action} type. The action itself takes a single argument - the object's identifier. In ASP, each action is written as $\textit{$<$action$>$}(\textit{$<$id$>$})$.
\end{itemize}

The domain independent rules for the OceanQA environment are as outlined in Appendix~\ref{appendix-al}, with the following addition:
\begin{equation}
  \neg holds(F, 0) \text{ :- } fluent(inertial, F), not \text{ } holds(F, 0).
\end{equation}

This rule ensures that the initial state of the system is complete for inertial fluents - all inertial fluents are either true or false. With this rule in the program there is no uncertainty about the system's initial state.

% While this isn't a requirement for $\mathcal{AL}$ systems, it simplifies the rest of the model since there is no uncertainty about the system's state.

Finally, we outline the domain dependent $\mathcal{AL}$ statements for the system:
\begin{itemize}
  \item The \textit{move} action causes the object to move 15 pixels in the direction of rotation. This means that, in frame $i+1$, the object is no longer in the position it was in during frame $i$. We use a Python function, $new\_pos$, in the ASP program to calculate the object's next position. This function is called using the $@$ symbol. The $\mathcal{AL}$ \textit{causal laws} for the move action are the following:
  \begin{gather*}
    move(\mathit{Id}) \textbf{ causes } position(@new\_pos(P, R), \mathit{Id}) \textbf{ if } position(P, \mathit{Id}), rotation(R, \mathit{Id}) \\
    move(\mathit{Id}) \textbf{ causes } \neg position(P, \mathit{Id}) \textbf{ if } position(P, \mathit{Id})
  \end{gather*}

  \item $\mathcal{AL}$ causal laws follow the same pattern for both rotation actions. The Python function, $new\_rot$, is used to calculate the new rotation for the object, it takes the previous rotation and the type of rotation as arguments. In the following $\mathcal{AL}$ causal laws \textit{$<$d$>$} is used to refer to the direction of rotation:
  \begin{gather*}
    rotate\_\textit{$<$d$>$}(\mathit{Id}) \textbf{ causes } rotation(@new\_rot(R, rotate\_\textit{$<$d$>$}) \textbf{ if } rotation(R, \mathit{Id}) \\
    rotate\_\textit{$<$d$>$}(\mathit{Id}) \textbf{ causes } \neg rotation(R, \mathit{Id}) \textbf{ if } rotation(R, \mathit{Id})
  \end{gather*}

  \item In order to ensure that objects are modelled as non-existent after they have disappeared, the following causal law is added:
  \begin{equation*}
    move(\mathit{Id}) \textbf{ causes } \neg exists(\mathit{Id}) \textbf{ if } exists(\mathit{Id}), disappear(\mathit{Id})
  \end{equation*}

  \item Finally, the following \textit{executability conditions} are added to reduce the size of the search space for the optimiser:
  \begin{gather*}
    \textbf{impossible } move(\mathit{Id}) \textbf{ if } \neg exists(\mathit{Id}) \\
    \textbf{impossible } rotate\_clockwise(\mathit{Id}) \textbf{ if } \neg exists(\mathit{Id}) \\
    \textbf{impossible } rotate\_anticlockwise(\mathit{Id}) \textbf{ if } \neg exists(\mathit{Id})
  \end{gather*}
\end{itemize}

The use of the $exists(\textit{$<$id$>$})$ fluent is an intuitive way of encoding the knowledge that when an object disappears it no longer exists, and, if an object does not exist, it cannot participate in any actions. Without this predicate, encoding knowledge like this would be tricky because the $disappear(\textit{$<$id$>$})$ fluent appears (at most) once during the video.

In the remainder of this section we diverge from $\mathcal{AL}$ orthodoxy in order to model effects. While it is possible to create a strict $\mathcal{AL}$ model of the entire OceanQA environment, a significant simplication can be achieved by cutting a few corners.

Effects can be considered to be similar to defined fluents in $\mathcal{AL}$, since, like defined fluents, they are triggered by some system state being true. Normally, for a defined fluent $f$ to be true at step $i$, a definition is given in terms of the system's state at step $i$, $\sigma_i$. However, the definitions for some effects require the entire transition $(\sigma_{i-1}, a_{i-1}, \sigma_i)$, where $a_{i-1}$ is the action which occurs at step $i-1$, to be given. For this reason we present effects using ASP rules with a combination of actions and $\mathcal{AL}$ fluents in the body. These rules can mostly be considered to compliment the $\mathcal{AL}$ model, rather than affect it. However, an exception is made for the rules which update the octopus' colour.

\begin{figure}
  \centering
  \begin{subfigure}{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{eat-fish-0.png}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{eat-fish-1.png}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{eat-fish-2.png}
  \end{subfigure}
  \caption{An example of the \textit{eat a fish} effect.}
  \label{fig:eat-fish}
\end{figure}

Firstly, for the \textit{eat a fish} (an example of which is shown in Figure~\ref{fig:eat-fish}) and \textit{eat a bag} effects, the following ASP rules are used:
\begin{equation}
  \begin{split}
    occurs\_\mathit{effect}(eat\_a\_fish(Octo), I) \text{ :- } & occurs\_action(move(Octo), I), \\
    & holds(class(fish, Fish), I), \\
    & holds(disappear(Fish), I).
  \end{split}
\end{equation}
\begin{equation}
  \begin{split}
    occurs\_\mathit{effect}(eat\_a\_bag(Octo), I) \text{ :- } & occurs\_action(move(Octo), I), \\
    & holds(class(bag, Bag), I), \\
    & holds(disappear(Bag), I), \\
    & holds(disappear(Octo), I).
  \end{split}
\end{equation}

We also need to ensure the octopus' colour is updated when it comes close to a rock, and that we keep track of any \textit{change colour} effects that occur. To do this we, firstly, use the following helper predicate:
\begin{equation}
  \begin{split}
    change\_colour(Old, New, Id, I-1) \text{ :- } & holds(class(octopus, Id), I), \\
    & holds(close(Id, IdRock), I), \\
    & holds(colour(Old, Id), I-1), \\
    & holds(class(rock, IdRock), I), \\
    & holds(colour(New, IdRock), I), \\
    & Old \text{ } != New, \\
    & step(I-1).
  \end{split}
\end{equation}

We also add the following ASP rule for the \textit{change colour} effect:
\begin{equation}
  occurs\_\mathit{effect}(change\_colour(Octo), I) \text{ :- } change\_colour(Old, New, Octo, I).
\end{equation}

Finally, the octopus' colour is updated using the follwing rules:
\begin{gather}
  holds(colour(New, Id), I+1) \text{ :- } change\_colour(Old, New, Id, I). \label{eqn:update-colour} \\
  \neg holds(colour(Old, Id), I+1) \text{ :- } change\_colour(Old, New, Id, I). \label{eqn:neg-update-colour}
\end{gather}

Rules~\ref{eqn:update-colour} and~\ref{eqn:neg-update-colour} alter the $\mathcal{AL}$ state, despite not being generated from $\mathcal{AL}$ statements. While this is not strictly speaking a true $\mathcal{AL}$ model, as mentioned above it is much simpler than the alternative.

% TODO Add another system transition diagram, with an example that shows how the AL models effects.


\subsection{Action Optimisation}

As we have seen, the $\mathcal{AL}$ model uses the $holds(\textit{$<$f$>$}, \textit{$<$i$>$})$ predicate to store its information, but the observed data uses $obs(\textit{$<$f$>$}, \textit{$<$i$>$})$. This distinction is by design; it separates the information (particularly that which is modelled by inertial fluents) in the two data models. However, we need some way of comparing the two models in order to find the optimal action combination.

Firstly, in order to ensure that both data models start with the same information, the fluents for the initial frame in the observed data are copied over to the $\mathcal{AL}$ model. Secondly, the ASP optimisation program generates all possible action combinations and applies each combination to the $\mathcal{AL}$ model to generate the data expected from that particular set of actions. These sets of action can be generated in ASP using the following rule:
\begin{equation}
  occurs\_action(A, I) : action(A) \text{ :- } step(I+1), I >= 0.
\end{equation}

Finally, in order to give each set of actions a score, the expected data is compared with the observed data and the number of mismatched fluents is counted. In ASP a \textit{weak constraint} can be used to assign a cost to an answer set. As explained in Chapter~\ref{chapter:background}, the ASP optimiser then searches for the answer set with the lowest cost. We use the following two weak constraints to optimise the action search:
\begin{gather}
  \text{:$\sim$ } \neg obs(exists(Id), I), holds(exists(Id), I). [1@2, exists(Id), I] \label{eqn:exists-opt} \\
  \text{:$\sim$ } obs(F, I), \neg holds(F, I). [1@1, F, I] \label{eqn:fluent-opt}
\end{gather}

Rule~\ref{eqn:exists-opt} is given a higher priority, so ASP searches for a set of answer sets which minimise the number of times the body is true before considering Rule~\ref{eqn:fluent-opt}. Rule~\ref{eqn:exists-opt} says that we prefer answer sets with the fewest mismatches due to the $exists\textit{$<$id$>$}$ fluent. Rule~\ref{eqn:fluent-opt}, on the other hand, says that we prefer answer sets with the fewest mismatches between all fluents. Rule~\ref{eqn:exists-opt} is given a higher priority, firstly, because it is more specific, and, secondly, because we consider an error in modelling the existence of an object as more significant than errors in modelling other fluents.

The following two hard constraints are also applied to ensure that basic rules of the OceanQA environment are not broken:
\begin{gather}
  \text{:- } obs(class(octopus, Id), I), occurs\_action(nothing(Id), I). \label{eqn:occurs-nothing-opt1} \\
  \text{:- } \neg obs(class(octopus, Id), I), \neg occurs\_action(nothing(Id), I). \label{eqn:occurs-nothing-opt2}
\end{gather}

Rule~\ref{eqn:occurs-nothing-opt1} rules out any answer sets where, for any frame in the video, the octopus exists and participates in the \textit{nothing} action. In a similar fashion, Rule~\ref{eqn:occurs-nothing-opt2} rules out any answer sets where the octopus does not exist in a frame, but still carries out an action other than \textit{nothing}.

The use of hard rather than weak constraints in Rules~\ref{eqn:occurs-nothing-opt1} and~\ref{eqn:occurs-nothing-opt2} improves the speed of the ASP optimisation. However, the weak constraints in Rules~\ref{eqn:exists-opt} and~\ref{eqn:fluent-opt} are necessary since the program must be able to deal with noisy data. If hard constraints were used instead any noise in the data could rule out all possible answer sets.

All of the above rules, as well as the ASP encoding of the $\mathcal{AL}$ model and the observed data, are run in a single ASP program which attempts to find the optimal set of actions for the video. Speed is a genuine concern for this optimisation; the ASP program has to evaluate $4^{32}$ action combinations, which could take a very long time. The ASP optimiser, however, uses optimisation strategies which can decrease the total search time. These algorithms include an ASP-specific extension of the branch-and-bound algorithm~\cite{asp:branch-and-bound}, which allows the optimiser to prune branches of the search tree if the branch is provably sub-optimal. For most videos in the evaluation dataset, the ASP optimisation is able to run in under 5 seconds. However, when the observed data is noisier, the algorithm has to explore many more answer sets, which takes significantly longer. This effect can be seen in Chapter~\ref{chapter:evaluation} when additional noise is added to the output of the object detector.


\section{Error Correction}

As we have already discussed, hardcoded models or components come with a number of drawbacks: they can be very complex to write; they have to be re-written for each new environment; and they may introduce human error or bias. However, hardcoded models also come with a key advantage: if the component has a deep understanding of the environment, it can attempt to correct errors in the input, or `de-noise' the data that it is given.

The hardcoded H-PERL model presented here attempts to correct only a single type of error - namely, an error in the object detection which leads to uncertainty in the object tracking. An example of a mistake made by the object detector is shown in Figure~\ref{fig:detector-error}. The uncertainty in the object tracker is due to the detector wrongly detecting two objects of the same type very close to each other; if there is only one of that type of object in the previous frame, the tracker will be unsure about which of the new objects should be assigned the previous object's identifier.

To combat this, we allow the tracker to assign the same identifier to multiple objects and then, during the event detection phase, the search space is extended to include searching over which object should be assigned the identifier. The algorithm can be outlined in more detail as follows:
\begin{enumerate}
  \item The object tracker works in the same way as before, except when multiple objects want to be assigned the same identifier. Unlike before, the tracker now assigns the identifier to all objects involved.

  \item For each frame, we keep track of the identifiers and the set of objects which are competing for each identifier.

  \item The ASP input in the event detection component is updated to include a choice rule which creates a set of object-identifier assignments. For each assignment, one of the competing objects is assigned the identifier and all others are assigned new, unused identifiers.

  \item Each assignment is evaluated using the optimisation outlined in Section~\ref{section:hardcoded-events} and the optimal assignment is chosen. In essence, this means that the object-identifier assignment which leads to the fewest differences between the data in the $\mathcal{AL}$ model and the observed data is chosen. Intuitively, this reflects the assumption that the assignment with the fewest mistakes is the one most likely to maximise the number of questions answered correctly.

  \item Finally, the chosen objects are assigned their respective identifiers, while the other objects are assigned new, unused identifiers. As mentioned in Chapter~\ref{chapter:h-perl}, this is the only occasion where a component of an H-PERL model can overwrite previously extracted information.
\end{enumerate}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.6\textwidth]{detection-error.png}
  \caption{An example of an error in the object detection. Two purple octopuses are detected in this frame. This leads to competition for the identifier of the `real' octopus.}
  \label{fig:detector-error}
\end{figure}

This algorithm for correcting errors is only possible when a model of the dataset's environment is known. Hence, the hardcoded model is the only model outlined in this report which is capable of error correction.

As mentioned in Section~\ref{section:hardcoded-events}, the amount of time the ASP optimiser takes can be a serious problem, especially if the data is very noisy, or in this case, if the object detector makes a lot of mistakes. However, our detector is highly accurate and so optimisation speed does not cause significant problems.

The hardcoded model has been designed to work with or without error correction. The full details of the model's performance in both modes of operation is outlined in Chapter~\ref{chapter:evaluation}.


\end{document}
