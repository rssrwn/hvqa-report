\documentclass[../report.tex]{subfiles}


\begin{document}


\chapter{Trained Model}
\label{chapter:trained}


In contrast to the hardcoded model, the trained H-PERL model does not use manually engineered relations or events components, and must therefore rely on using components which can be trained. The trained model also uses the QA-data version of the OceanQA dataset, rather than the full-data version which the hardcoded model was able to use to train its properties component. This means that the trained model needs to rely on the data contained in QA pairs alone to train its components.

As with the hardcoded model, full performance evaluation details of the trained model and some of its components can be found in Chapter~\ref{chapter:evaluation}.


\section{Properties}

As mentioned in Chapter~\ref{chapter:dataset}, property questions in the OceanQA dataset ask the model to find a property value for a specific object. This object, however, can contain a reference to a property value. This means that, in some cases, knowledge of object properties is required in order to find the specified object in the frame. For example, if a question asked ``What colour was the upward-facing fish in frame 12?", and there three fish, each with unique rotations, in frame 12, one would need knowledge of object properties in order to select the correct image of the fish. This causes a major problem when collating the training data for the properties component; the model needs a trained property extractor in order to find the images to train the property extractor with.

In this section we propose a solution to overcome this problem which utilises semi-supervised learning, in order to label all of the objects in the dataset with property values. Once these labels have been found, the property component can be trained in the same way as the hardcoded model, outlined in Chapter~\ref{chapter:hardcoded}.

The first step of the algorithm for finding these labels involves training an autoencoder neural network to extract a 16-dimensional latent vector from each object image. This network is trained in an unsupervised manner using a sample of 40000 of the objects detected by the object detector in the training data, where each object type is equally represented in the sample. The architecture of the network is shown in Figure~\ref{fig:ae-arch}. Each object image is resized to 16x16 pixels and the network is trained with a learning rate of $0.001$ for 5 epochs.

% TODO find nicer way of 16x16

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{ae-arch}
  \caption{An illustration of the autoencoder architecture. Although not shown here, the network contains batch normalisation layers between each pair of convolution layers. FM stands for feature maps, and the dimensions of each feature maps are given as $(\textit{height}, \textit{width}, \textit{number of feature maps})$.}
  \label{fig:ae-arch}
\end{figure}

The autoencoder allows the component to work with the latent vectors of objects rather than raw object images. At this stage, every object in the training data is encoded using the autoencoder and stored in vector form. After the autoencoder has been trained and all the objects have been encoded, the properties component splits objects in groups based on their class. The component then proceeds to apply the following high-level algorithm, which is described in further detail below, to each object type, $t_i$, individually:
\begin{enumerate}
  \item The vectors of the objects with type $t_i$ are clustered and each cluster is assigned an integer identifier, $c_i$.
  \item The QA pairs will label a number of the objects in the training data with some or all of their property values. ASP can be used to find a mapping from each $c_i$ to a set of property-value pairs.
  \item Once this mapping is known, all of the objects of type $t_i$ in the training data can be labelled. The algorithm for finding these labels is outlined below.
\end{enumerate}

As mentioned above, when the property value labels have been found for all objects of all types, the property component can be trained using the same method as the hardcoded model, discussed in Chapter~\ref{chapter:hardcoded}.


% Train the properties component in _ steps:
% 1. Train an autoencoder to encode object images
% 2. Cluster the latent space separately for each class (the number of clusters is an estimate based on QA)
% 3. Find the optimal property values for each cluster, for each class using ASP
% 4. Label the full training dataset using: AE, cluster centres and label->property mapping
% 5. Train the property component as if the full dataset was given (ie. same as train_from_hardcoded)


\section{Relations}


\section{Events}



\end{document}
